{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "import numpy\n",
    "import pandas as pd\n",
    "#Importing necessary packages\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "forest = pd.read_csv(\"forestfires.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "forest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.drop([\"month\",\"day\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 29 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   FFMC           517 non-null    float64\n",
      " 1   DMC            517 non-null    float64\n",
      " 2   DC             517 non-null    float64\n",
      " 3   ISI            517 non-null    float64\n",
      " 4   temp           517 non-null    float64\n",
      " 5   RH             517 non-null    int64  \n",
      " 6   wind           517 non-null    float64\n",
      " 7   rain           517 non-null    float64\n",
      " 8   area           517 non-null    float64\n",
      " 9   dayfri         517 non-null    int64  \n",
      " 10  daymon         517 non-null    int64  \n",
      " 11  daysat         517 non-null    int64  \n",
      " 12  daysun         517 non-null    int64  \n",
      " 13  daythu         517 non-null    int64  \n",
      " 14  daytue         517 non-null    int64  \n",
      " 15  daywed         517 non-null    int64  \n",
      " 16  monthapr       517 non-null    int64  \n",
      " 17  monthaug       517 non-null    int64  \n",
      " 18  monthdec       517 non-null    int64  \n",
      " 19  monthfeb       517 non-null    int64  \n",
      " 20  monthjan       517 non-null    int64  \n",
      " 21  monthjul       517 non-null    int64  \n",
      " 22  monthjun       517 non-null    int64  \n",
      " 23  monthmar       517 non-null    int64  \n",
      " 24  monthmay       517 non-null    int64  \n",
      " 25  monthnov       517 non-null    int64  \n",
      " 26  monthoct       517 non-null    int64  \n",
      " 27  monthsep       517 non-null    int64  \n",
      " 28  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(1)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "forest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    378\n",
       "large    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.loc[forest[\"size_category\"]=='small','size_category']=0\n",
    "forest.loc[forest[\"size_category\"]=='large','size_category']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    378\n",
       "1    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 29 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   FFMC           517 non-null    float64\n",
      " 1   DMC            517 non-null    float64\n",
      " 2   DC             517 non-null    float64\n",
      " 3   ISI            517 non-null    float64\n",
      " 4   temp           517 non-null    float64\n",
      " 5   RH             517 non-null    int64  \n",
      " 6   wind           517 non-null    float64\n",
      " 7   rain           517 non-null    float64\n",
      " 8   area           517 non-null    float64\n",
      " 9   dayfri         517 non-null    int64  \n",
      " 10  daymon         517 non-null    int64  \n",
      " 11  daysat         517 non-null    int64  \n",
      " 12  daysun         517 non-null    int64  \n",
      " 13  daythu         517 non-null    int64  \n",
      " 14  daytue         517 non-null    int64  \n",
      " 15  daywed         517 non-null    int64  \n",
      " 16  monthapr       517 non-null    int64  \n",
      " 17  monthaug       517 non-null    int64  \n",
      " 18  monthdec       517 non-null    int64  \n",
      " 19  monthfeb       517 non-null    int64  \n",
      " 20  monthjan       517 non-null    int64  \n",
      " 21  monthjul       517 non-null    int64  \n",
      " 22  monthjun       517 non-null    int64  \n",
      " 23  monthmar       517 non-null    int64  \n",
      " 24  monthmay       517 non-null    int64  \n",
      " 25  monthnov       517 non-null    int64  \n",
      " 26  monthoct       517 non-null    int64  \n",
      " 27  monthsep       517 non-null    int64  \n",
      " 28  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(1)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "forest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest[\"size_category\"] = pd.to_numeric(forest.size_category, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 29 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   FFMC           517 non-null    float64\n",
      " 1   DMC            517 non-null    float64\n",
      " 2   DC             517 non-null    float64\n",
      " 3   ISI            517 non-null    float64\n",
      " 4   temp           517 non-null    float64\n",
      " 5   RH             517 non-null    int64  \n",
      " 6   wind           517 non-null    float64\n",
      " 7   rain           517 non-null    float64\n",
      " 8   area           517 non-null    float64\n",
      " 9   dayfri         517 non-null    int64  \n",
      " 10  daymon         517 non-null    int64  \n",
      " 11  daysat         517 non-null    int64  \n",
      " 12  daysun         517 non-null    int64  \n",
      " 13  daythu         517 non-null    int64  \n",
      " 14  daytue         517 non-null    int64  \n",
      " 15  daywed         517 non-null    int64  \n",
      " 16  monthapr       517 non-null    int64  \n",
      " 17  monthaug       517 non-null    int64  \n",
      " 18  monthdec       517 non-null    int64  \n",
      " 19  monthfeb       517 non-null    int64  \n",
      " 20  monthjan       517 non-null    int64  \n",
      " 21  monthjul       517 non-null    int64  \n",
      " 22  monthjun       517 non-null    int64  \n",
      " 23  monthmar       517 non-null    int64  \n",
      " 24  monthmay       517 non-null    int64  \n",
      " 25  monthnov       517 non-null    int64  \n",
      " 26  monthoct       517 non-null    int64  \n",
      " 27  monthsep       517 non-null    int64  \n",
      " 28  size_category  517 non-null    int64  \n",
      "dtypes: float64(8), int64(21)\n",
      "memory usage: 117.3 KB\n"
     ]
    }
   ],
   "source": [
    "forest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = forest.iloc[:,:-1]\n",
    "y = forest.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthdec  monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  \\\n",
       "0           0         0         0         0         0         1         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         1         0   \n",
       "4           0         0         0         0         0         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthnov  monthoct  monthsep  \n",
       "0           0         0         0  \n",
       "1           0         1         0  \n",
       "2           0         1         0  \n",
       "3           0         0         0  \n",
       "4           0         0         0  \n",
       "..        ...       ...       ...  \n",
       "512         0         0         0  \n",
       "513         0         0         0  \n",
       "514         0         0         0  \n",
       "515         0         0         0  \n",
       "516         1         0         0  \n",
       "\n",
       "[517 rows x 28 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size_category\n",
       "0                0\n",
       "1                0\n",
       "2                0\n",
       "3                0\n",
       "4                0\n",
       "..             ...\n",
       "512              1\n",
       "513              1\n",
       "514              1\n",
       "515              0\n",
       "516              0\n",
       "\n",
       "[517 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.754024e-15</td>\n",
       "      <td>3.070830e-16</td>\n",
       "      <td>7.387171e-17</td>\n",
       "      <td>-3.865380e-17</td>\n",
       "      <td>2.005703e-16</td>\n",
       "      <td>3.362881e-16</td>\n",
       "      <td>-2.676776e-16</td>\n",
       "      <td>-2.841054e-16</td>\n",
       "      <td>-1.274502e-16</td>\n",
       "      <td>4.874674e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.304582e+01</td>\n",
       "      <td>-1.715608e+00</td>\n",
       "      <td>-2.179108e+00</td>\n",
       "      <td>-1.980578e+00</td>\n",
       "      <td>-2.876943e+00</td>\n",
       "      <td>-1.796637e+00</td>\n",
       "      <td>-2.021098e+00</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.063453e-02</td>\n",
       "      <td>-6.606652e-01</td>\n",
       "      <td>-4.448281e-01</td>\n",
       "      <td>-5.535954e-01</td>\n",
       "      <td>-5.842379e-01</td>\n",
       "      <td>-6.924563e-01</td>\n",
       "      <td>-7.361236e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.732292e-01</td>\n",
       "      <td>-4.020255e-02</td>\n",
       "      <td>4.691190e-01</td>\n",
       "      <td>-1.364774e-01</td>\n",
       "      <td>7.082076e-02</td>\n",
       "      <td>-1.403660e-01</td>\n",
       "      <td>-9.833712e-03</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-1.938429e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.089598e-01</td>\n",
       "      <td>4.927389e-01</td>\n",
       "      <td>6.696628e-01</td>\n",
       "      <td>3.904086e-01</td>\n",
       "      <td>6.741643e-01</td>\n",
       "      <td>5.344111e-01</td>\n",
       "      <td>4.929823e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-9.870852e-02</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.007353e+00</td>\n",
       "      <td>2.819865e+00</td>\n",
       "      <td>1.261610e+00</td>\n",
       "      <td>1.033538e+01</td>\n",
       "      <td>2.484195e+00</td>\n",
       "      <td>3.417549e+00</td>\n",
       "      <td>3.007063e+00</td>\n",
       "      <td>2.157228e+01</td>\n",
       "      <td>1.695111e+01</td>\n",
       "      <td>2.254407e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -1.754024e-15  3.070830e-16  7.387171e-17 -3.865380e-17  2.005703e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.304582e+01 -1.715608e+00 -2.179108e+00 -1.980578e+00 -2.876943e+00   \n",
       "25%   -8.063453e-02 -6.606652e-01 -4.448281e-01 -5.535954e-01 -5.842379e-01   \n",
       "50%    1.732292e-01 -4.020255e-02  4.691190e-01 -1.364774e-01  7.082076e-02   \n",
       "75%    4.089598e-01  4.927389e-01  6.696628e-01  3.904086e-01  6.741643e-01   \n",
       "max    1.007353e+00  2.819865e+00  1.261610e+00  1.033538e+01  2.484195e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   3.362881e-16 -2.676776e-16 -2.841054e-16 -1.274502e-16  4.874674e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.796637e+00 -2.021098e+00 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "25%   -6.924563e-01 -7.361236e-01 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "50%   -1.403660e-01 -9.833712e-03 -7.326831e-02 -1.938429e-01 -4.435755e-01   \n",
       "75%    5.344111e-01  4.929823e-01 -7.326831e-02 -9.870852e-02 -4.435755e-01   \n",
       "max    3.417549e+00  3.007063e+00  2.157228e+01  1.695111e+01  2.254407e+00   \n",
       "\n",
       "       ...            18            19            20            21  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 22            23            24            25            26  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 27  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model1\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=28,activation='relu'))\n",
    "model.add(layers.Dense(8,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model1\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "35/35 [==============================] - 1s 14ms/step - loss: 0.6402 - accuracy: 0.6213 - val_loss: 0.7038 - val_accuracy: 0.6491\n",
      "Epoch 2/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7504 - val_loss: 0.6937 - val_accuracy: 0.6784\n",
      "Epoch 3/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7504 - val_loss: 0.6878 - val_accuracy: 0.6784\n",
      "Epoch 4/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7699 - val_loss: 0.6846 - val_accuracy: 0.6784\n",
      "Epoch 5/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7724 - val_loss: 0.6808 - val_accuracy: 0.6784\n",
      "Epoch 6/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7629 - val_loss: 0.6774 - val_accuracy: 0.6784\n",
      "Epoch 7/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7798 - val_loss: 0.6711 - val_accuracy: 0.6784\n",
      "Epoch 8/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7443 - val_loss: 0.6667 - val_accuracy: 0.6784\n",
      "Epoch 9/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7880 - val_loss: 0.6655 - val_accuracy: 0.6784\n",
      "Epoch 10/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7757 - val_loss: 0.6576 - val_accuracy: 0.6725\n",
      "Epoch 11/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7731 - val_loss: 0.6535 - val_accuracy: 0.6784\n",
      "Epoch 12/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7736 - val_loss: 0.6509 - val_accuracy: 0.6842\n",
      "Epoch 13/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8015 - val_loss: 0.6504 - val_accuracy: 0.6842\n",
      "Epoch 14/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7937 - val_loss: 0.6466 - val_accuracy: 0.6842\n",
      "Epoch 15/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8135 - val_loss: 0.6466 - val_accuracy: 0.6901\n",
      "Epoch 16/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8045 - val_loss: 0.6476 - val_accuracy: 0.6959\n",
      "Epoch 17/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8190 - val_loss: 0.6478 - val_accuracy: 0.6959\n",
      "Epoch 18/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8414 - val_loss: 0.6454 - val_accuracy: 0.7018\n",
      "Epoch 19/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8244 - val_loss: 0.6438 - val_accuracy: 0.7193\n",
      "Epoch 20/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.6445 - val_accuracy: 0.7193\n",
      "Epoch 21/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8031 - val_loss: 0.6457 - val_accuracy: 0.7193\n",
      "Epoch 22/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8135 - val_loss: 0.6474 - val_accuracy: 0.7310\n",
      "Epoch 23/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8046 - val_loss: 0.6507 - val_accuracy: 0.7310\n",
      "Epoch 24/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8678 - val_loss: 0.6524 - val_accuracy: 0.7310\n",
      "Epoch 25/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8387 - val_loss: 0.6544 - val_accuracy: 0.7368\n",
      "Epoch 26/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8674 - val_loss: 0.6560 - val_accuracy: 0.7310\n",
      "Epoch 27/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8573 - val_loss: 0.6551 - val_accuracy: 0.7310\n",
      "Epoch 28/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8358 - val_loss: 0.6568 - val_accuracy: 0.7310\n",
      "Epoch 29/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8580 - val_loss: 0.6614 - val_accuracy: 0.7485\n",
      "Epoch 30/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8715 - val_loss: 0.6612 - val_accuracy: 0.7544\n",
      "Epoch 31/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8756 - val_loss: 0.6644 - val_accuracy: 0.7602\n",
      "Epoch 32/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8608 - val_loss: 0.6641 - val_accuracy: 0.7602\n",
      "Epoch 33/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.9000 - val_loss: 0.6716 - val_accuracy: 0.7602\n",
      "Epoch 34/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8647 - val_loss: 0.6703 - val_accuracy: 0.7661\n",
      "Epoch 35/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8619 - val_loss: 0.6759 - val_accuracy: 0.7661\n",
      "Epoch 36/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8830 - val_loss: 0.6777 - val_accuracy: 0.7661\n",
      "Epoch 37/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9059 - val_loss: 0.6831 - val_accuracy: 0.7719\n",
      "Epoch 38/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9184 - val_loss: 0.6847 - val_accuracy: 0.7778\n",
      "Epoch 39/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9287 - val_loss: 0.6899 - val_accuracy: 0.7836\n",
      "Epoch 40/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9056 - val_loss: 0.6939 - val_accuracy: 0.7778\n",
      "Epoch 41/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9164 - val_loss: 0.7024 - val_accuracy: 0.7895\n",
      "Epoch 42/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9179 - val_loss: 0.7056 - val_accuracy: 0.7895\n",
      "Epoch 43/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9089 - val_loss: 0.7070 - val_accuracy: 0.7953\n",
      "Epoch 44/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9131 - val_loss: 0.7176 - val_accuracy: 0.8012\n",
      "Epoch 45/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9271 - val_loss: 0.7212 - val_accuracy: 0.8070\n",
      "Epoch 46/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9539 - val_loss: 0.7276 - val_accuracy: 0.8012\n",
      "Epoch 47/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9320 - val_loss: 0.7323 - val_accuracy: 0.8070\n",
      "Epoch 48/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9523 - val_loss: 0.7435 - val_accuracy: 0.8070\n",
      "Epoch 49/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9287 - val_loss: 0.7444 - val_accuracy: 0.8070\n",
      "Epoch 50/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9433 - val_loss: 0.7556 - val_accuracy: 0.8012\n",
      "Epoch 51/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9456 - val_loss: 0.7620 - val_accuracy: 0.7836\n",
      "Epoch 52/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9480 - val_loss: 0.7636 - val_accuracy: 0.7895\n",
      "Epoch 53/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9541 - val_loss: 0.7710 - val_accuracy: 0.7953\n",
      "Epoch 54/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9513 - val_loss: 0.7761 - val_accuracy: 0.7836\n",
      "Epoch 55/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9522 - val_loss: 0.7872 - val_accuracy: 0.7836\n",
      "Epoch 56/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9516 - val_loss: 0.7932 - val_accuracy: 0.7778\n",
      "Epoch 57/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9683 - val_loss: 0.7956 - val_accuracy: 0.7895\n",
      "Epoch 58/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9428 - val_loss: 0.8079 - val_accuracy: 0.7661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9764 - val_loss: 0.8049 - val_accuracy: 0.7778\n",
      "Epoch 60/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9705 - val_loss: 0.8148 - val_accuracy: 0.7719\n",
      "Epoch 61/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9664 - val_loss: 0.8335 - val_accuracy: 0.7719\n",
      "Epoch 62/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9622 - val_loss: 0.8250 - val_accuracy: 0.7602\n",
      "Epoch 63/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9620 - val_loss: 0.8455 - val_accuracy: 0.7719\n",
      "Epoch 64/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9449 - val_loss: 0.8554 - val_accuracy: 0.7661\n",
      "Epoch 65/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9627 - val_loss: 0.8441 - val_accuracy: 0.7719\n",
      "Epoch 66/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9602 - val_loss: 0.8566 - val_accuracy: 0.7661\n",
      "Epoch 67/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9808 - val_loss: 0.8665 - val_accuracy: 0.7778\n",
      "Epoch 68/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9728 - val_loss: 0.8757 - val_accuracy: 0.7778\n",
      "Epoch 69/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9741 - val_loss: 0.8783 - val_accuracy: 0.7661\n",
      "Epoch 70/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9831 - val_loss: 0.8816 - val_accuracy: 0.7719\n",
      "Epoch 71/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9666 - val_loss: 0.8887 - val_accuracy: 0.7719\n",
      "Epoch 72/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9871 - val_loss: 0.8931 - val_accuracy: 0.7836\n",
      "Epoch 73/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9885 - val_loss: 0.9093 - val_accuracy: 0.7661\n",
      "Epoch 74/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9774 - val_loss: 0.9129 - val_accuracy: 0.7719\n",
      "Epoch 75/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9831 - val_loss: 0.9187 - val_accuracy: 0.7661\n",
      "Epoch 76/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9825 - val_loss: 0.9290 - val_accuracy: 0.7719\n",
      "Epoch 77/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9914 - val_loss: 0.9396 - val_accuracy: 0.7719\n",
      "Epoch 78/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9927 - val_loss: 0.9473 - val_accuracy: 0.7661\n",
      "Epoch 79/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9828 - val_loss: 0.9618 - val_accuracy: 0.7602\n",
      "Epoch 80/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9858 - val_loss: 0.9582 - val_accuracy: 0.7719\n",
      "Epoch 81/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9858 - val_loss: 0.9750 - val_accuracy: 0.7719\n",
      "Epoch 82/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9816 - val_loss: 0.9725 - val_accuracy: 0.7778\n",
      "Epoch 83/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9857 - val_loss: 0.9962 - val_accuracy: 0.7661\n",
      "Epoch 84/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9984 - val_loss: 0.9972 - val_accuracy: 0.7661\n",
      "Epoch 85/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9974 - val_loss: 1.0052 - val_accuracy: 0.7778\n",
      "Epoch 86/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9955 - val_loss: 1.0164 - val_accuracy: 0.7661\n",
      "Epoch 87/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9976 - val_loss: 1.0289 - val_accuracy: 0.7836\n",
      "Epoch 88/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9947 - val_loss: 1.0312 - val_accuracy: 0.7719\n",
      "Epoch 89/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9912 - val_loss: 1.0385 - val_accuracy: 0.7778\n",
      "Epoch 90/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9980 - val_loss: 1.0444 - val_accuracy: 0.7778\n",
      "Epoch 91/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9965 - val_loss: 1.0515 - val_accuracy: 0.7778\n",
      "Epoch 92/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9984 - val_loss: 1.0685 - val_accuracy: 0.7836\n",
      "Epoch 93/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9947 - val_loss: 1.0671 - val_accuracy: 0.7778\n",
      "Epoch 94/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9996 - val_loss: 1.0830 - val_accuracy: 0.7661\n",
      "Epoch 95/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9942 - val_loss: 1.0757 - val_accuracy: 0.7778\n",
      "Epoch 96/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9989 - val_loss: 1.1014 - val_accuracy: 0.7778\n",
      "Epoch 97/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.1063 - val_accuracy: 0.7778\n",
      "Epoch 98/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9972 - val_loss: 1.1070 - val_accuracy: 0.7719\n",
      "Epoch 99/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.7719\n",
      "Epoch 100/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9997 - val_loss: 1.1318 - val_accuracy: 0.7661\n",
      "Epoch 101/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.1301 - val_accuracy: 0.7661\n",
      "Epoch 102/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9968 - val_loss: 1.1310 - val_accuracy: 0.7661\n",
      "Epoch 103/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.7719\n",
      "Epoch 104/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.1618 - val_accuracy: 0.7719\n",
      "Epoch 105/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.7778\n",
      "Epoch 106/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9991 - val_loss: 1.1607 - val_accuracy: 0.7661\n",
      "Epoch 107/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.1693 - val_accuracy: 0.7778\n",
      "Epoch 108/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.1705 - val_accuracy: 0.7719\n",
      "Epoch 109/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.1855 - val_accuracy: 0.7719\n",
      "Epoch 110/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.7778\n",
      "Epoch 111/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.7661\n",
      "Epoch 112/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.2054 - val_accuracy: 0.7778\n",
      "Epoch 113/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.7836\n",
      "Epoch 114/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.2197 - val_accuracy: 0.7836\n",
      "Epoch 115/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.2048 - val_accuracy: 0.7836\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.2262 - val_accuracy: 0.7836\n",
      "Epoch 117/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.7836\n",
      "Epoch 118/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2436 - val_accuracy: 0.7836\n",
      "Epoch 119/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.2443 - val_accuracy: 0.7836\n",
      "Epoch 120/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.2517 - val_accuracy: 0.7836\n",
      "Epoch 121/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.2607 - val_accuracy: 0.7953\n",
      "Epoch 122/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.2579 - val_accuracy: 0.7895\n",
      "Epoch 123/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7895\n",
      "Epoch 124/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.7895\n",
      "Epoch 125/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.2796 - val_accuracy: 0.8012\n",
      "Epoch 126/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.2880 - val_accuracy: 0.7895\n",
      "Epoch 127/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.7895\n",
      "Epoch 128/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.7953\n",
      "Epoch 129/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3151 - val_accuracy: 0.8012\n",
      "Epoch 130/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 0.7953\n",
      "Epoch 131/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3233 - val_accuracy: 0.7953\n",
      "Epoch 132/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.3186 - val_accuracy: 0.7953\n",
      "Epoch 133/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3383 - val_accuracy: 0.8012\n",
      "Epoch 134/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.3318 - val_accuracy: 0.8012\n",
      "Epoch 135/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.8070\n",
      "Epoch 136/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.8070\n",
      "Epoch 137/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3572 - val_accuracy: 0.8070\n",
      "Epoch 138/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.8012\n",
      "Epoch 139/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3638 - val_accuracy: 0.8070\n",
      "Epoch 140/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.8129\n",
      "Epoch 141/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.3826 - val_accuracy: 0.8070\n",
      "Epoch 142/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.3791 - val_accuracy: 0.8129\n",
      "Epoch 143/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9998 - val_loss: 1.3829 - val_accuracy: 0.8129\n",
      "Epoch 144/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4239 - val_accuracy: 0.8070\n",
      "Epoch 145/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9925 - val_loss: 1.3974 - val_accuracy: 0.8129\n",
      "Epoch 146/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3981 - val_accuracy: 0.8129\n",
      "Epoch 147/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.8129\n",
      "Epoch 148/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.4050 - val_accuracy: 0.8129\n",
      "Epoch 149/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.4158 - val_accuracy: 0.8129\n",
      "Epoch 150/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4160 - val_accuracy: 0.8187\n",
      "Epoch 151/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4252 - val_accuracy: 0.8129\n",
      "Epoch 152/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.8129\n",
      "Epoch 153/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.4375 - val_accuracy: 0.8187\n",
      "Epoch 154/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4515 - val_accuracy: 0.8129\n",
      "Epoch 155/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4526 - val_accuracy: 0.8129\n",
      "Epoch 156/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.4479 - val_accuracy: 0.8187\n",
      "Epoch 157/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4623 - val_accuracy: 0.8187\n",
      "Epoch 158/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.4664 - val_accuracy: 0.8187\n",
      "Epoch 159/250\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4816 - val_accuracy: 0.8070\n",
      "Epoch 160/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4698 - val_accuracy: 0.8187\n",
      "Epoch 161/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4929 - val_accuracy: 0.8187\n",
      "Epoch 162/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4874 - val_accuracy: 0.8187\n",
      "Epoch 163/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.5006 - val_accuracy: 0.8187\n",
      "Epoch 164/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5070 - val_accuracy: 0.8129\n",
      "Epoch 165/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5016 - val_accuracy: 0.8187\n",
      "Epoch 166/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.5192 - val_accuracy: 0.8129\n",
      "Epoch 167/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5243 - val_accuracy: 0.8187\n",
      "Epoch 168/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5310 - val_accuracy: 0.8129\n",
      "Epoch 169/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5366 - val_accuracy: 0.8187\n",
      "Epoch 170/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5400 - val_accuracy: 0.8129\n",
      "Epoch 171/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5415 - val_accuracy: 0.8304\n",
      "Epoch 172/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5477 - val_accuracy: 0.8187\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5557 - val_accuracy: 0.8246\n",
      "Epoch 174/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.8187\n",
      "Epoch 175/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5627 - val_accuracy: 0.8246\n",
      "Epoch 176/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9920 - val_loss: 1.5701 - val_accuracy: 0.8246\n",
      "Epoch 177/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5753 - val_accuracy: 0.8246\n",
      "Epoch 178/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5832 - val_accuracy: 0.8246\n",
      "Epoch 179/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5888 - val_accuracy: 0.8363\n",
      "Epoch 180/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.8363\n",
      "Epoch 181/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6072 - val_accuracy: 0.8304\n",
      "Epoch 182/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5991 - val_accuracy: 0.8421\n",
      "Epoch 183/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6148 - val_accuracy: 0.8304\n",
      "Epoch 184/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6227 - val_accuracy: 0.8363\n",
      "Epoch 185/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.8363\n",
      "Epoch 186/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.6361 - val_accuracy: 0.8363\n",
      "Epoch 187/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.8363\n",
      "Epoch 188/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6425 - val_accuracy: 0.8363\n",
      "Epoch 189/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6510 - val_accuracy: 0.8363\n",
      "Epoch 190/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6518 - val_accuracy: 0.8363\n",
      "Epoch 191/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6467 - val_accuracy: 0.8480\n",
      "Epoch 192/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6632 - val_accuracy: 0.8363\n",
      "Epoch 193/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6719 - val_accuracy: 0.8363\n",
      "Epoch 194/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6814 - val_accuracy: 0.8421\n",
      "Epoch 195/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6804 - val_accuracy: 0.8421\n",
      "Epoch 196/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6869 - val_accuracy: 0.8421\n",
      "Epoch 197/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6938 - val_accuracy: 0.8421\n",
      "Epoch 198/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6978 - val_accuracy: 0.8421\n",
      "Epoch 199/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7095 - val_accuracy: 0.8421\n",
      "Epoch 200/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7188 - val_accuracy: 0.8421\n",
      "Epoch 201/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.7191 - val_accuracy: 0.8421\n",
      "Epoch 202/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7244 - val_accuracy: 0.8421\n",
      "Epoch 203/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7273 - val_accuracy: 0.8421\n",
      "Epoch 204/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7373 - val_accuracy: 0.8421\n",
      "Epoch 205/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.8421\n",
      "Epoch 206/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7441 - val_accuracy: 0.8421\n",
      "Epoch 207/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7584 - val_accuracy: 0.8421\n",
      "Epoch 208/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7635 - val_accuracy: 0.8421\n",
      "Epoch 209/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.8421\n",
      "Epoch 210/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7707 - val_accuracy: 0.8421\n",
      "Epoch 211/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7846 - val_accuracy: 0.8421\n",
      "Epoch 212/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.8421\n",
      "Epoch 213/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7931 - val_accuracy: 0.8421\n",
      "Epoch 214/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8021 - val_accuracy: 0.8421\n",
      "Epoch 215/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8040 - val_accuracy: 0.8421\n",
      "Epoch 216/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8155 - val_accuracy: 0.8421\n",
      "Epoch 217/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8262 - val_accuracy: 0.8421\n",
      "Epoch 218/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8252 - val_accuracy: 0.8421\n",
      "Epoch 219/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8322 - val_accuracy: 0.8421\n",
      "Epoch 220/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8345 - val_accuracy: 0.8421\n",
      "Epoch 221/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8447 - val_accuracy: 0.8421\n",
      "Epoch 222/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8450 - val_accuracy: 0.8421\n",
      "Epoch 223/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8598 - val_accuracy: 0.8421\n",
      "Epoch 224/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8731 - val_accuracy: 0.8421\n",
      "Epoch 225/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8750 - val_accuracy: 0.8421\n",
      "Epoch 226/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8658 - val_accuracy: 0.8421\n",
      "Epoch 227/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8830 - val_accuracy: 0.8421\n",
      "Epoch 228/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8881 - val_accuracy: 0.8421\n",
      "Epoch 229/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 9.8612e-04 - accuracy: 1.0000 - val_loss: 1.8977 - val_accuracy: 0.8421\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.8421\n",
      "Epoch 231/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9025 - val_accuracy: 0.8421\n",
      "Epoch 232/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 8.9970e-04 - accuracy: 1.0000 - val_loss: 1.9188 - val_accuracy: 0.8421\n",
      "Epoch 233/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 9.9897e-04 - accuracy: 1.0000 - val_loss: 1.9252 - val_accuracy: 0.8421\n",
      "Epoch 234/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9229 - val_accuracy: 0.8421\n",
      "Epoch 235/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9325 - val_accuracy: 0.8421\n",
      "Epoch 236/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9402 - val_accuracy: 0.8421\n",
      "Epoch 237/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 9.2560e-04 - accuracy: 1.0000 - val_loss: 1.9452 - val_accuracy: 0.8421\n",
      "Epoch 238/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 9.0540e-04 - accuracy: 1.0000 - val_loss: 1.9445 - val_accuracy: 0.8421\n",
      "Epoch 239/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 7.2001e-04 - accuracy: 1.0000 - val_loss: 1.9639 - val_accuracy: 0.8421\n",
      "Epoch 240/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.6497e-04 - accuracy: 1.0000 - val_loss: 1.9723 - val_accuracy: 0.8421\n",
      "Epoch 241/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8.6522e-04 - accuracy: 1.0000 - val_loss: 1.9732 - val_accuracy: 0.8421\n",
      "Epoch 242/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 8.5759e-04 - accuracy: 1.0000 - val_loss: 1.9764 - val_accuracy: 0.8421\n",
      "Epoch 243/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 9.6957e-04 - accuracy: 1.0000 - val_loss: 1.9788 - val_accuracy: 0.8421\n",
      "Epoch 244/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.7205e-04 - accuracy: 1.0000 - val_loss: 1.9925 - val_accuracy: 0.8421\n",
      "Epoch 245/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7.7589e-04 - accuracy: 1.0000 - val_loss: 1.9859 - val_accuracy: 0.8421\n",
      "Epoch 246/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 5.5604e-04 - accuracy: 1.0000 - val_loss: 2.0141 - val_accuracy: 0.8421\n",
      "Epoch 247/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 9.2221e-04 - accuracy: 1.0000 - val_loss: 2.0106 - val_accuracy: 0.8421\n",
      "Epoch 248/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.7916e-04 - accuracy: 1.0000 - val_loss: 2.0173 - val_accuracy: 0.8421\n",
      "Epoch 249/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 6.4094e-04 - accuracy: 1.0000 - val_loss: 2.0191 - val_accuracy: 0.8421\n",
      "Epoch 250/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6.9722e-04 - accuracy: 1.0000 - val_loss: 2.0243 - val_accuracy: 0.8421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x233687f2820>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model1\n",
    "model.fit(X_standardized,y, validation_split=0.33, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 998us/step - loss: 0.6700 - accuracy: 0.9478\n",
      "accuracy: 94.78%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model1\n",
    "scores = model.evaluate(X_standardized,y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model2\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=28,activation='relu'))\n",
    "    model.add(Dense(5,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.952, total=   1.1s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.817, total=   1.1s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.738, total=   1.1s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.806, total=   1.0s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.874, total=   1.2s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=1.000, total=   2.1s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.837, total=   2.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.893, total=   2.2s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   11.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.874, total=   2.4s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   13.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.903, total=   2.1s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.990, total=   3.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.913, total=   3.8s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.893, total=   3.4s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.796, total=   3.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.825, total=   3.5s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.971, total=   1.0s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.750, total=   0.9s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.709, total=   0.8s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.748, total=   1.0s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.816, total=   0.8s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.981, total=   1.5s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.894, total=   1.4s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.922, total=   1.6s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.893, total=   1.4s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.854, total=   1.4s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.990, total=   2.3s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.894, total=   2.3s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.883, total=   2.1s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.903, total=   2.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.883, total=   2.3s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.962, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.750, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.553, total=   0.9s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B07F160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.680, total=   0.7s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C894280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.709, total=   0.8s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336AFD40D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=0.952, total=   1.0s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336860A5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=0.846, total=   1.2s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B630820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=0.903, total=   1.0s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DEFA940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=50, epochs=50, score=0.913, total=   1.0s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E54040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=0.854, total=   1.1s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B6309D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.990, total=   1.4s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C8434C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.885, total=   1.4s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DF52040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.922, total=   1.4s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E54430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.893, total=   1.6s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C894790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.874, total=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Create the model2\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,50]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9128640651702881, using {'batch_size': 50, 'epochs': 100}\n",
      "0.8373412966728211,0.07176008940192898 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9012882590293885,0.05433396099349528 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.883681857585907,0.06847744834775633 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.7985997080802918,0.09284668038913571 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9089805722236634,0.04190635279460872 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9109036684036255,0.04040178247418451 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7306571960449219,0.1328060203008201 with: {'batch_size': 50, 'epochs': 10}\n",
      "0.8935959696769714,0.039090490542244505 with: {'batch_size': 50, 'epochs': 50}\n",
      "0.9128640651702881,0.041977666833576 with: {'batch_size': 50, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results Model 2\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E4BCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=1.000, total=   1.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E54700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.750, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CC0E280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.524, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CD0A9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.680, total=   0.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000233687CE5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.699, total=   1.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CD0A8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=1.000, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336E2D4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.750, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B6301F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.641, total=   1.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E54700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.718, total=   0.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C894A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.845, total=   0.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336E0B60D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.962, total=   0.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B07F280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.788, total=   1.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E545E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.786, total=   0.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B5381F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.680, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000233687CEA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.845, total=   1.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DEFA5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=1.000, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CD0A3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.750, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336851CAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.524, total=   1.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DEFACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.680, total=   1.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C843160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.699, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336E0560D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.990, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369C45940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.750, total=   1.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CD0AA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.524, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DEFAC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.680, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E54310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.757, total=   1.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CD0A280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.942, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000233687CE790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.750, total=   0.8s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336E0B0160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.524, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C6A0DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.767, total=   0.8s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E54790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.854, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CB45160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=1.000, total=   0.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000233685D39D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.750, total=   1.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E54310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.524, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369C45790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.680, total=   0.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023367682280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.699, total=   1.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CD0A700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.971, total=   0.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B630940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.760, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B000A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.612, total=   1.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000233687CE5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.748, total=   1.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B000820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.699, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CD0AAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.971, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C8943A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.750, total=   1.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E543A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.524, total=   0.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B07F1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.709, total=   0.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DFAB430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.699, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   41.4s finished\n"
     ]
    }
   ],
   "source": [
    "#Model 3\n",
    "#Tuning of Hyperparameters:- Learning rate and Drop out rate\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.812135922908783, using {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.7907767057418823,0.12334683292088218 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.812135922908783,0.09183032557822593 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.7403099298477173,0.15051646491703782 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.7675877571105957,0.13969277155200413 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.7578043341636658,0.11869410848998828 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.7306385397911072,0.14303040893944743 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results Model3\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336CB9F3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV]  activation_function=softmax, init=uniform, score=0.990, total=   8.3s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.856, total=   9.0s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.874, total=   9.4s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.903, total=   8.2s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   34.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.874, total=   8.6s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   43.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.981, total=   8.2s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   51.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.856, total=   8.2s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   59.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.961, total=   8.4s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.893, total=   7.9s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.903, total=   8.1s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.990, total=   8.9s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.856, total=   7.8s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.942, total=   8.5s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.903, total=   9.4s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.883, total=   8.6s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=1.000, total=   7.5s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.885, total=   7.9s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.913, total=   7.8s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.922, total=   7.8s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.922, total=   7.7s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=1.000, total=   8.5s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.885, total=   7.5s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.922, total=   8.4s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.932, total=   7.7s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.893, total=   7.9s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=1.000, total=   7.6s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.750, total=   8.8s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.524, total=   7.5s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.680, total=   7.7s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.699, total=   7.9s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=1.000, total=   8.4s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.952, total=   7.9s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.913, total=   8.3s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.942, total=   7.8s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.932, total=   7.7s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=1.000, total=   8.0s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.942, total=   8.4s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.922, total=   8.4s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.932, total=   7.5s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.942, total=   8.3s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=1.000, total=   8.5s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.750, total=   8.1s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.524, total=   7.7s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.680, total=   8.5s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.699, total=   7.8s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=1.000, total=   8.3s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.942, total=   7.5s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.913, total=   7.6s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.942, total=   8.3s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.951, total=   7.8s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=1.000, total=   7.4s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.942, total=   8.2s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.913, total=   7.6s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.951, total=   7.4s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.951, total=   8.2s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=1.000, total=   7.6s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.750, total=   7.9s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.524, total=   7.4s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.680, total=   7.4s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.699, total=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  8.1min finished\n"
     ]
    }
   ],
   "source": [
    "#Model 4\n",
    "#Tuning of Hyperparameters:- Activation Function and Kernel Initializer\n",
    "# Defining the model\n",
    "\n",
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs =250)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.951568341255188, using {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.8993278503417969,0.047971400089614105 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.9187639951705933,0.04585941078833258 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.9148618340492248,0.0470002668216763 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.9283793807029724,0.0383830825548724 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.9264376282691955,0.04077561473635935 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.9476661682128906,0.02920387577181428 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.9476848363876342,0.027161376719325194 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.9496265888214112,0.02837555031791039 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.951568341255188,0.028100803645324232 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results Model 4\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=1.000, total=   6.6s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.843, total=   7.0s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   13.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.924, total=   6.6s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   20.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=1.000, total=   6.6s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   26.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.826, total=   7.3s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   33.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.919, total=   6.7s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   40.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=8, score=1.000, total=   6.8s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   47.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=8, score=0.837, total=   7.1s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   54.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=8, score=0.919, total=   7.2s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=8, neuron2=2, score=1.000, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.855, total=   6.5s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.936, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=1.000, total=   6.2s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.820, total=   6.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.930, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=1.000, total=   6.8s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.826, total=   6.5s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.924, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=1.000, total=   7.7s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.855, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.901, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=1.000, total=   7.2s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.826, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.936, total=   7.0s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=1.000, total=   7.1s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.837, total=   7.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.924, total=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "#Tuning of Hyperparameter :-Number of Neurons in activation layer Model 5\n",
    "# Defining the model\n",
    "\n",
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 28,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 250)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(3),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.930232564608256, using {'neuron1': 8, 'neuron2': 2}\n",
      "0.9224806229273478,0.06410014378014862 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.9147286812464396,0.07125883311398311 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.9186046520868937,0.06645903138564027 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.930232564608256,0.059480661078541275 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.9166666666666666,0.07420229880214328 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.9166666666666666,0.07141677743156151 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.9186046520868937,0.06060657497246498 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.9205426375071207,0.07204509110593683 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9205426375071207,0.06651552078052284 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results Model 5\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model6\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=28,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=1.000, total=   1.2s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.865, total=   1.3s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.874, total=   1.1s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.913, total=   1.0s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.874, total=   1.2s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=1.000, total=   2.2s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.962, total=   2.2s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   10.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.913, total=   2.2s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   12.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.951, total=   2.3s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   14.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.942, total=   2.3s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=1.000, total=   3.7s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.942, total=   3.9s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.913, total=   3.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.961, total=   3.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.922, total=   4.0s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.990, total=   1.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.846, total=   1.0s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.845, total=   1.0s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.893, total=   1.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.893, total=   1.1s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=1.000, total=   1.6s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.942, total=   1.7s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.903, total=   1.6s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.951, total=   1.5s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.951, total=   1.7s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=1.000, total=   2.4s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.942, total=   2.4s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.913, total=   2.3s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.951, total=   2.2s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.961, total=   2.3s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.990, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.769, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.777, total=   1.0s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DFABDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.825, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B000310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=10, score=0.854, total=   0.8s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336E35DD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=1.000, total=   1.1s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023369E4BB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=0.942, total=   1.3s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B07FB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=0.903, total=   1.1s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336DFAB4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=50, epochs=50, score=0.951, total=   1.1s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B630E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=50, epochs=50, score=0.932, total=   1.2s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C843AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=1.000, total=   1.5s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B07FE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.962, total=   1.5s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336C6DBD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.913, total=   1.4s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002335E2FA310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.951, total=   1.6s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002336B07F1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=50, epochs=100, score=0.971, total=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Create the model6 \n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs =250)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9592979788780213, using {'batch_size': 50, 'epochs': 100}\n",
      "0.9051157593727112,0.050201542241246726 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9534727334976196,0.02842611902243071 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9476848483085633,0.031047757361927462 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.8935212850570678,0.05294107584535176 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9496265888214112,0.030919047421574003 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9535100936889649,0.028360213244869974 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.8431852102279663,0.08000544160384467 with: {'batch_size': 50, 'epochs': 10}\n",
      "0.9457430958747863,0.0316559971796948 with: {'batch_size': 50, 'epochs': 50}\n",
      "0.9592979788780213,0.028410807649881475 with: {'batch_size': 50, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results Model 6\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
